<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Research | Mgs M Luthfi Ramadhan </title> <meta name="author" content="Mgs M Luthfi Ramadhan"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%CF%80&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://luthfi118.github.io/research/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Mgs M</span> Luthfi Ramadhan </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item active"> <a class="nav-link" href="/research/">Research <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/articles/index.html">Articles </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item dropdown active"> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus <span class="sr-only">(current)</span> </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="https://luthfi-ramadhan.github.io/" rel="external nofollow noopener" target="_blank">About</a> <div class="dropdown-divider"></div> <a class="dropdown-item active" href="/research/">Research</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/articles/">Articles</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/cv/">CV</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Research</h1> <p class="post-description"></p> </header> <article> <script src="/assets/js/bibsearch.js?1bc438ca9037884cc579601c09afd847" type="module"></script> <p><input type="text" id="bibsearch" spellcheck="false" autocomplete="off" class="search bibsearch-form-input" placeholder="Type to filter"></p> <div class="publications"> <h2 class="bibliography">2024</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://ieeeaccess.ieee.org/" rel="external nofollow noopener" target="_blank">IEEE Access</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/access-gagraphic-3510774-480.webp 480w,/assets/img/publication_preview/access-gagraphic-3510774-800.webp 800w,/assets/img/publication_preview/access-gagraphic-3510774-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/access-gagraphic-3510774.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="access-gagraphic-3510774.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10776969" class="col-sm-8"> <div class="title">Time-Distributed Vision Transformer Stacked With Transformer for Heart Failure Detection Based on Echocardiography Video</div> <div class="author"> Mgs M. Luthfi Ramadhan, Adyatma W. A. Nugraha Yudha, Muhammad Febrian Rachmadi, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Kevin Moses Hanky Jr Tandayu, Lies Dina Liastuti, Wisnu Jatmiko' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>IEEE Access</em>, Dec 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ACCESS.2024.3510774" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10776969" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Time-Distributed_Vision_Transformer_Stacked_With_Transformer_for_Heart_Failure_Detection_Based_on_Echocardiography_Video.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2024.3510774" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:Y0pCki6q_DkC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Heart failure is a disease many consider to be the number one global cause of death. Despite its mortality, heart failure is still underdiagnosed clinically, especially in a remote area that experiences cardiologists shortage. Existing studies have employed artificial intelligence to help with heart failure screening and diagnosis processes based on echocardiography videos. Specifically, most existing studies use a convolutional neural network that only captures the local context of an image hindering it from learning the global context of an image. Moreover, the frame sampling algorithms only sample certain consecutive frames which makes it questionable whether the dynamic of the left ventricle during a cardiac cycle is included. This study proposed a novel deep learning model consisting of a time-distributed vision transformer stacked with a transformer. The time-distributed vision transformer learns the spatial feature and then feeds the result to the transformer to learn the temporal feature and make the final prediction afterward. We also proposed a frame sampling algorithm by squeezing the video and sampling the frame after a certain interval. Consequently, the video still contains the sequential information up until the end of the video with some in-between frames removed by a certain interval. Thus, the dynamic of the left ventricle is preserved. Our proposed method achieved an F1 score of 95.81%, 96.19%, and 93.43% for the apical four chamber view, apical two chamber view, and parasternal long axis view respectively. The overall trustworthiness of our model is quantified using the NetTrustScore and achieved a score of 0.9712, 0.9767, and 0.9527 for the apical four chamber view, apical two chamber view, and parasternal long axis view respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10776969</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramadhan, Mgs M. Luthfi and Yudha, Adyatma W. A. Nugraha and Rachmadi, Muhammad Febrian and Tandayu, Kevin Moses Hanky Jr and Liastuti, Lies Dina and Jatmiko, Wisnu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Time-Distributed Vision Transformer Stacked With Transformer for Heart Failure Detection Based on Echocardiography Video}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">dec</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{182438-182454}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Echocardiography;Transformers;Convolutional neural networks;Feature extraction;Hafnium;Computer vision;Heart;Cardiovascular diseases;Data analysis;Wrapping;Deep learning;pattern recognition;heart failure;echocardiography;computer vision}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2024.3510774}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://ieeeaccess.ieee.org/" rel="external nofollow noopener" target="_blank">IEEE Access</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/access-gagraphic-3361287-480.webp 480w,/assets/img/publication_preview/access-gagraphic-3361287-800.webp 800w,/assets/img/publication_preview/access-gagraphic-3361287-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/access-gagraphic-3361287.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="access-gagraphic-3361287.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10418211" class="col-sm-8"> <div class="title">Building Damage Assessment Using Feature Concatenated Siamese Neural Network</div> <div class="author"> Mgs M. Luthfi Ramadhan, Grafika Jati, and Wisnu Jatmiko </div> <div class="periodical"> <em>IEEE Access</em>, Jan 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ACCESS.2024.3361287" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10418211" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Building_Damage_Assessment_Using_Feature_Concatenated_Siamese_Neural_Network.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2024.3361287" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:UeHWp8X0CEIC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Fast and accurate post-earthquake building damage assessment is an important task to do to define search and rescue procedures. Many approaches have been proposed to automate this process by using artificial intelligence, some of which use handcrafted features that are considered inefficient. This research proposed end-to-end building damage assessment based on a Siamese neural network. We modify the network by adding a feature concatenation mechanism to enrich the data feature. This concatenation mechanism creates different features based on each output from the convolution block. It concatenates them into a high-dimensional vector so that the feature representation is more likely to be linearly separable, resulting in better discrimination capability than the standard siamese. Our model was evaluated through three experimental scenarios where we performed classification of G1 or G5, G1-G4 or G5, and all the five grades of EMS-98 building damage description. Our models are superior to the standard Siamese neural network and state-of-the-art in this field. Our model obtains f1-scores of 79.47%, 54.09%, 40.64% and accuracy scores of 87.24%, 95.28%, and 42.57% for the first, second, and third experiments, respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10418211</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramadhan, Mgs M. Luthfi and Jati, Grafika and Jatmiko, Wisnu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Building Damage Assessment Using Feature Concatenated Siamese Neural Network}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jan</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{19100-19116}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Neurons;Feature extraction;Earthquakes;Point cloud compression;Laser radar;Classification algorithms;Disaster management;Neural networks;Classification;deep learning;disaster;earthquake;LiDAR;siamese neural network}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2024.3361287}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JIKI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Screenshot%202024-12-22%20110252-480.webp 480w,/assets/img/publication_preview/Screenshot%202024-12-22%20110252-800.webp 800w,/assets/img/publication_preview/Screenshot%202024-12-22%20110252-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Screenshot%202024-12-22%20110252.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Screenshot 2024-12-22 110252.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="ramadhan2024alternative" class="col-sm-8"> <div class="title">An alternative for kernel SVM when stacked with a neural network</div> <div class="author"> Mgs M Luthfi Ramadhan </div> <div class="periodical"> <em>Jurnal Ilmu Komputer dan Informasi</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.21609/jiki.v17i1.1172" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://jiki.cs.ui.ac.id/index.php/jiki/article/view/1172" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/1172-Article%20Text-3490-1-10-20240225.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.21609/jiki.v17i1.1172" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:Tyk-4Ss8FVUC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Many studies stack SVM and neural network by utilzing SVM as an output layer of the neural network. However, those studies use kernel before the SVM which is unnecessary. In this study, we proposed an alternative to kernel SVM and proved why kernel is unnecessary when the SVM is stacked on top of neural network. The experiments is done on Dublin City LiDAR data. In this study, we stack PointNet and SVM but instead of using kernel, we simply utilize the last hidden layer of the PointNet. As an alternative to the SVM kernel, this study performs dimension expansion by increasing the number of neurons in the last hidden layer. We proved that expanding the dimension by increasing the number of neurons in the last hidden layer can increase the F-Measure score and it performs better than RBF kernel both in term of F-Measure score and computation time.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">ramadhan2024alternative</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{An alternative for kernel SVM when stacked with a neural network}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramadhan, Mgs M Luthfi}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Jurnal Ilmu Komputer dan Informasi}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{17}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--7}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">feb</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21609/jiki.v17i1.1172}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JIKI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Screenshot%202024-12-24%20235527-480.webp 480w,/assets/img/publication_preview/Screenshot%202024-12-24%20235527-800.webp 800w,/assets/img/publication_preview/Screenshot%202024-12-24%20235527-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Screenshot%202024-12-24%20235527.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Screenshot 2024-12-24 235527.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Fazry_Mgs M Luthfi Ramadhan_Jatmiko_2024" class="col-sm-8"> <div class="title">Improving Remote Sensing Change Detection Via Locality Induction on Feed-forward Vision Transformer</div> <div class="author"> Lhuqita Fazry, Mgs M Luthfi Ramadhan, and Wisnu Jatmiko </div> <div class="periodical"> <em>Jurnal Ilmu Komputer dan Informasi</em>, Feb 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.21609/jiki.v17i1.1188" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://jiki.cs.ui.ac.id/index.php/jiki/article/view/1188" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/1188-Article%20Text-3493-1-10-20240225.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.21609/jiki.v17i1.1188" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:IjCSPb-OGe4C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>The main objective of Change Detection (CD) is to gather change information from bi-temporal remote sensing images. The recent development of the CD method makes use of the recently proposed Vision Transformer (ViT) backbone. Despite ViT being superior to Convolutional Neural Networks (CNN) at modeling long-range dependencies, ViT lacks a locality mechanism, a critical property of pixels that comprise natural images, including remote sensing images. This issue leads to segmentation artifacts such as imperfect changed region boundaries on the predicted change map. To address this problem, we propose LocalCD, a novel CD method that imposes the locality mechanism into the Transformer encoder. Particularly, it replaces the Transformer’s feed-forward network using an efficient depth-wise convolution between two 1 \times 1 convolutions. LocalCD outperforms ChangeFormer by a significant margin. Specifically, it achieves an F1-score of 0.9548 and 0.9243 on CDD and LEVIR-CD datasets.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Fazry_Mgs</span> <span class="err">M</span> <span class="err">Luthfi</span> <span class="err">Ramadhan_Jatmiko_2024,</span>
  <span class="err">title</span> <span class="err">=</span> <span class="err">{Improving</span> <span class="err">Remote</span> <span class="err">Sensing</span> <span class="err">Change</span> <span class="err">Detection</span> <span class="err">Via</span> <span class="err">Locality</span> <span class="err">Induction</span> <span class="err">on</span> <span class="err">Feed-forward</span> <span class="err">Vision</span> <span class="err">Transformer</span><span class="p">}</span><span class="c">,</span>
  <span class="c">volume = {17},</span>
  <span class="c">url = {https://jiki.cs.ui.ac.id/index.php/jiki/article/view/1188},</span>
  <span class="c">doi = {10.21609/jiki.v17i1.1188},</span>
  <span class="c">number = {1},</span>
  <span class="c">journal = {Jurnal Ilmu Komputer dan Informasi},</span>
  <span class="c">author = {Fazry, Lhuqita and Ramadhan, Mgs M Luthfi and Jatmiko, Wisnu},</span>
  <span class="c">year = {2024},</span>
  <span class="c">month = feb,</span>
  <span class="c">dimensions = {true},</span>
  <span class="c">pages = {37-48}</span>
<span class="c">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2023</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#00369f"> <a href="https://ieeeaccess.ieee.org/" rel="external nofollow noopener" target="_blank">IEEE Access</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/access-gagraphic-3292531-480.webp 480w,/assets/img/publication_preview/access-gagraphic-3292531-800.webp 800w,/assets/img/publication_preview/access-gagraphic-3292531-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/access-gagraphic-3292531.jpg" class="preview z-depth-1 rounded" width="100%" height="auto" alt="access-gagraphic-3292531.jpg" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="10173482" class="col-sm-8"> <div class="title">Change Detection of High-Resolution Remote Sensing Images Through Adaptive Focal Modulation on Hierarchical Feature Maps</div> <div class="author"> Lhuqita Fazry, Mgs M. Luthfi Ramadhan, and Wisnu Jatmiko </div> <div class="periodical"> <em>IEEE Access</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/ACCESS.2023.3292531" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/10173482" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Change_Detection_of_High-Resolution_Remote_Sensing_Images_Through_Adaptive_Focal_Modulation_on_Hierarchical_Feature_Maps.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/ACCESS.2023.3292531" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:qjMakFHDy7sC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-6-4285F4?logo=googlescholar&amp;labelColor=beige" alt="6 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>One of the major challenges in the change detection (CD) of high-resolution remote sensing images is the high requirement for computational resources. Besides, to get the best change detection result, it must spot only the important changes while omitting unimportant ones, which requires learning complex interactions between multi-scale objects on the images. Despite Convolution Neural Network (CNN) efficiently extracting features from such images, it has a limited receptive field resulting in sub-optimal representation. On the other hand, Vision Transformer (ViT) can capture long-range dependencies. Still, it suffers from quadratic complexity concerning the number of image patches, especially for high-resolution images. Furthermore, both approach can not model the interactions among multi-scale image patches, which is essential for a model to fully understand the natural images. We propose FocalCD, a CD method based on a recently proposed focal modulation architecture capable of learning short and long dependencies to solve this problem. It is attention-free and does not suffer from quadratic complexity. Also, it supports learning multi-scale interaction by adaptively selecting the discriminator regions from multi-scale levels. Besides the efficient yet powerful encoder, FocalCD has an effective multi-scale feature fusion and pyramidal decoder network. FocalCD achieves strong empirical results on various CD datasets, including CDD, LEVIR-CD, and WHU-CD. It reaches F1 scores of 0.9851, 0.952, and 0.9616 on datasets CDD, LEVIR-CD, and WHU-CD outperforming state-of-the-art CD methods while having comparable or even lower computation complexity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">10173482</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Fazry, Lhuqita and Ramadhan, Mgs M. Luthfi and Jatmiko, Wisnu}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE Access}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Change Detection of High-Resolution Remote Sensing Images Through Adaptive Focal Modulation on Hierarchical Feature Maps}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{69072-69090}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Feature extraction;Transformers;Task analysis;Remote sensing;Convolution;Computer architecture;Decoding;Change detection;FocalCD;focal modulation;multi-scale feature fusion;vision transformer}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ACCESS.2023.3292531}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">JIKI</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Screenshot%202024-12-24%20234204-480.webp 480w,/assets/img/publication_preview/Screenshot%202024-12-24%20234204-800.webp 800w,/assets/img/publication_preview/Screenshot%202024-12-24%20234204-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Screenshot%202024-12-24%20234204.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Screenshot 2024-12-24 234204.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="Azizi_Ramadhan_Jatmiko_2023" class="col-sm-8"> <div class="title">Encoder-Decoder with Atrous Spatial Pyramid Pooling for Left Ventricle Segmentation in Echocardiography</div> <div class="author"> Fityan Azizi, Mgs M Luthfi Ramadhan, and Wisnu Jatmiko </div> <div class="periodical"> <em>Jurnal Ilmu Komputer dan Informasi</em>, Jul 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.21609/jiki.v16i2.1165" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://jiki.cs.ui.ac.id/index.php/jiki/article/view/1165" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/1165-Article%20Text-3234-1-10-20230703.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.21609/jiki.v16i2.1165" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:2osOgNQ5qMEC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-0-4285F4?logo=googlescholar&amp;labelColor=beige" alt="0 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Assessment of cardiac function using echocardiography is an essential and widely used method. Assessment by manually labeling the left ventricle area can generally be time-consuming, error-prone, and has interobserver variability. Thus, automatic delineation of the left ventricle area is necessary so that the assessment can be carried out effectively and efficiently. In this study, encoder-decoder based deep learning model for left ventricle segmentation in echocardiography was developed using the effective CNN U-Net encoder and combined with the deeplabv3+ decoder which has efficient performance and is able to produce sharper and more accurate segmentation results. Furthermore, the Atrous Spatial Pyramid Pooling module were added to the encoder to improve feature extraction. Tested on the Echonet-Dynamic dataset, the proposed model gives better results than the U-Net, DeeplabV3+, and DeeplabV3 models by producing a dice similarity coefficient of 92.87%. The experimental results show that combining the U-Net encoder and DeeplabV3+ decoder is able to provide increased performance compared to previous studies.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">Azizi_Ramadhan_Jatmiko_2023</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Encoder-Decoder with Atrous Spatial Pyramid Pooling for Left Ventricle Segmentation in Echocardiography}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{16}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21609/jiki.v16i2.1165}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{2}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Jurnal Ilmu Komputer dan Informasi}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Azizi, Fityan and Ramadhan, Mgs M Luthfi and Jatmiko, Wisnu}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{163-169}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2022</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IWBIS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/azizi3-6_2060-large-480.webp 480w,/assets/img/publication_preview/azizi3-6_2060-large-800.webp 800w,/assets/img/publication_preview/azizi3-6_2060-large-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/azizi3-6_2060-large.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="azizi3-6_2060-large.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9924685" class="col-sm-8"> <div class="title">Modified MultiResUNet for Left Ventricle Segmentation from Echocardiographic Images</div> <div class="author"> Fityan Azizi, Akbar Fathur Sani, Rinto Priambodo, and <span class="more-authors" title="click to view 4 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '4 more authors' ? 'Wisma Chaerul Karunianto, Mgs M Luthfi Ramadhan, Muhammad Febrian Rachmadi, Wisnu Jatmiko' : '4 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">4 more authors</span> </div> <div class="periodical"> <em>In 2022 7th International Workshop on Big Data and Information Security (IWBIS)</em>, Oct 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IWBIS56557.2022.9924685" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9924685" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Modified_MultiResUNet_for_Left_Ventricle_Segmentation_from_Echocardiographic_Images.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/IWBIS56557.2022.9924685" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:9yKSN-GCB0IC" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-1-4285F4?logo=googlescholar&amp;labelColor=beige" alt="1 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>An accurate assessment of heart function is crucial in diagnosing the cardiovascular disease. One way to evaluate or detect the disease can use echocardiography, by detecting systolic and diastolic volumes. However, manual human assessments can be time-consuming and error-prone due to the low resolution of the image. One way to detect heart failure on echocardiogram is by segmenting the left ventricle on the echocardiogram using deep learning. In this study, we modified the MultiResUNet model for left ventricle segmentation in echocardiography images by adding Atrous Spatial Pyramid Pooling block and Attention block. The use of multires blocks from MultiResUnet is able to overcome the problem of multi-resolution segmentation objects, where the segmentation objects have different sizes. This problem has similar characteristics to echocardiographic images, where the systole and diastole segmentation objects have different sizes from each other. Performance measure were evaluated using Echonet-Dynamic dataset. The proposed model achieves dice coefficient of 92%, giving an additional 2% performance result compared to the MultiResUNet.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9924685</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Azizi, Fityan and Sani, Akbar Fathur and Priambodo, Rinto and Karunianto, Wisma Chaerul and Ramadhan, Mgs M Luthfi and Rachmadi, Muhammad Febrian and Jatmiko, Wisnu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2022 7th International Workshop on Big Data and Information Security (IWBIS)}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Modified MultiResUNet for Left Ventricle Segmentation from Echocardiographic Images}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{33-38}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Heart;Deep learning;Image segmentation;Echocardiography;Conferences;Information security;Manuals;Heart Function;Echocardiography;Semantic Segmentation;Deep Learning}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IWBIS56557.2022.9924685}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100" style="background-color:#009f36"> <a href="https://actamedindones.org/index.php/ijim" rel="external nofollow noopener" target="_blank">Acta med. Indones.</a> </abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/Screenshot%202024-12-22%20104023-480.webp 480w,/assets/img/publication_preview/Screenshot%202024-12-22%20104023-800.webp 800w,/assets/img/publication_preview/Screenshot%202024-12-22%20104023-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/Screenshot%202024-12-22%20104023.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="Screenshot 2024-12-22 104023.png" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="LIFES" class="col-sm-8"> <div class="title">Learning Intelligent for Effective Sonography (LIFES) Model for Rapid Diagnosis of Heart Failure in Echocardiography</div> <div class="author"> Lies Dina Liastuti, Bambang Budi Siswanto, Renan Sukmawan, and <span class="more-authors" title="click to view 10 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '10 more authors' ? 'Wisnu Jatmiko, Idrus Alwi, Budi Wiweko, Aria Kekalih, Yosilia Nursakina, Rindayu Yusticia Indira Putri, Grafika Jati, Mgs M Luthfi Ramadhan, Ericko Govardi, Aqsha Azhary Nur' : '10 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">10 more authors</span> </div> <div class="periodical"> <em></em> Jul 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.actamedindones.org/index.php/ijim/article/view/2185" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/2185-8960-1-PB.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-pmid="" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:d1gkVwhDpl0C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Background: The accuracy of an artificial intelligence model based on echocardiography video data in the diagnosis of heart failure (HF) called LIFES (Learning Intelligent for Effective Sonography) was investigated. Methods: A cross-sectional diagnostic test was conducted using consecutive sampling of HF and normal patients’ echocardiography data. The gold-standard comparison was HF diagnosis established by expert cardiologists based on clinical data and echocardiography. After pre-processing, the AI model is built based on Long-Short Term Memory (LSTM) using independent variable estimation and video classification techniques. The model will classify the echocardiography video data into normal and heart failure category. Statistical analysis was carried out to calculate the value of accuracy, area under the curve (AUC), sensitivity, specificity, positive predictive value (PPV), negative predictive value (NPV), and likelihood ratio (LR). Results: A total of 138 patients with HF admitted to Harapan Kita National Heart Center from January 2020 to October 2021 were selected as research subjects. The first scenario yielded decent diagnostic performance for distinguishing between heart failure and normal patients. In this model, the overall diagnostic accuracy of A2C, A4C, PLAX-view were 92,96%, 90,62% and 88,28%, respectively. The automated ML-derived approach had the best overall performance using the 2AC view, with a misclassification rate of only 7,04%. Conclusion: The LIFES model was feasible, accurate, and quick in distinguishing between heart failure and normal patients through series of echocardiography images.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">LIFES</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Learning {Intelligent} for {Effective} {Sonography} ({LIFES}) {Model} for {Rapid} {Diagnosis} of {Heart} {Failure} in {Echocardiography}}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{54}</span><span class="p">,</span>
  <span class="na">language</span> <span class="p">=</span> <span class="s">{en}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Liastuti, Lies Dina and Siswanto, Bambang Budi and Sukmawan, Renan and Jatmiko, Wisnu and Alwi, Idrus and Wiweko, Budi and Kekalih, Aria and Nursakina, Yosilia and Putri, Rindayu Yusticia Indira and Jati, Grafika and Ramadhan, Mgs M Luthfi and Govardi, Ericko and Nur, Aqsha Azhary}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">jul</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2021</h2> <ol class="bibliography"><li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">IWBIS</abbr> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/9631844-fig-7-source-large-480.webp 480w,/assets/img/publication_preview/9631844-fig-7-source-large-800.webp 800w,/assets/img/publication_preview/9631844-fig-7-source-large-1400.webp 1400w," type="image/webp" sizes="200px"></source> <img src="/assets/img/publication_preview/9631844-fig-7-source-large.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="9631844-fig-7-source-large.gif" data-zoomable="" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="9631844" class="col-sm-8"> <div class="title">Collapsed Building Detection Using Residual Siamese Neural Network On LiDAR Data</div> <div class="author"> Mgs M Luthfi Ramadhan, Grafika Jati, Machmud Roby Alhamidi, and <span class="more-authors" title="click to view 3 more authors" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '3 more authors' ? 'Riskyana Dewi Intan P, Muhammad Hafizhuddin Hilman, Wisnu Jatmiko' : '3 more authors'; var cursorPosition=0; var textAdder=setInterval(function(){ element.html(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">3 more authors</span> </div> <div class="periodical"> <em>In 2021 6th International Workshop on Big Data and Information Security (IWBIS)</em>, Oct 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="https://doi.org/10.1109/IWBIS53353.2021.9631844" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">DOI</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/9631844" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="/assets/pdf/Collapsed_Building_Detection_Using_Residual_Siamese_Neural_Network_On_LiDAR_Data.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> </div> <div class="badges"> <span class="__dimensions_badge_embed__" data-doi="10.1109/IWBIS53353.2021.9631844" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 3px;"></span> <a href="https://scholar.google.com/citations?view_op=view_citation&amp;hl=en&amp;user=5BG0z7AAAAAJ&amp;citation_for_view=5BG0z7AAAAAJ:u5HHmVD_uO8C" aria-label="Google Scholar link" role="button" rel="external nofollow noopener" target="_blank"> <img src="https://img.shields.io/badge/scholar-3-4285F4?logo=googlescholar&amp;labelColor=beige" alt="3 Google Scholar citations"> </a> </div> <div class="abstract hidden"> <p>Evaluation of buildings is crucial to aid emergency response but it costs a lot of resources to do it manually. Many approaches have been proposed to automate the process using artificial intelligence. Most of them, use handcrafted feature, difference calculation between pre-disaster and post-disaster feature, and a classifier model separately. In this study, the process from feature extraction, feature difference and classification are represented by a single model which is siamese neural network. Furthermore, we modify siamese neural network by implementing residual connection for feature concatenation purposes. We evaluate our model on Kumamoto Prefecture earthquake LiDAR data. The result shows the modified model is able to outperform the baseline model with Accuracy and F-measure of 90.91% and 79.28% respectively.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">9631844</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ramadhan, Mgs M Luthfi and Jati, Grafika and Alhamidi, Machmud Roby and P, Riskyana Dewi Intan and Hilman, Muhammad Hafizhuddin and Jatmiko, Wisnu}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2021 6th International Workshop on Big Data and Information Security (IWBIS)}</span><span class="p">,</span>
  <span class="na">dimensions</span> <span class="p">=</span> <span class="s">{true}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Collapsed Building Detection Using Residual Siamese Neural Network On LiDAR Data}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">oct</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{29-34}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Laser radar;Costs;Neural networks;Buildings;Earthquakes;Information security;Euclidean distance;earthquake;siamese neural network;deep learning;collapsed building assessment}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/IWBIS53353.2021.9631844}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Mgs M Luthfi Ramadhan. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a>. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script>for(var wechatModal=document.getElementById("WeChatMod"),wechatBtn=document.querySelectorAll('[id="WeChatBtn"]'),i=0;i<wechatBtn.length;i++)wechatBtn[i].onclick=function(){wechatModal.style.display="block"};window.onclick=function(t){t.target==wechatModal&&(wechatModal.style.display="none")};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-research",title:"Research",description:"",section:"Navigation",handler:()=>{window.location.href="/research/"}},{id:"nav-articles",title:"Articles",description:"",section:"Navigation",handler:()=>{window.location.href="/articles/index.html"}},{id:"nav-cv",title:"CV",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"dropdown-about",title:"About",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-research",title:"Research",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-articles",title:"Articles",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-cv",title:"CV",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"post-to-be-without-consenting-to",title:'To Be Without Consenting to <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/illumination/to-be-without-consenting-to-97a5ee22f7cd?source=rss-7af47edd640c------2","_blank")}},{id:"post-determinism-the-chains-of-causality",title:'Determinism: The Chains of Causality <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/illumination/determinism-the-chains-of-causality-68789ec8770c?source=rss-7af47edd640c------2","_blank")}},{id:"post-hypothesis-testing-simplified",title:'Hypothesis Testing Simplified <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://www.cantorsparadise.com/hypothesis-testing-simplified-e1eaa71dee73?source=rss-7af47edd640c------2","_blank")}},{id:"post-amor-fati",title:'Amor Fati <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/intuition/amor-fati-af56eea1ecdd?source=rss-7af47edd640c------2","_blank")}},{id:"post-gradient-descent-simplified",title:'Gradient Descent Simplified <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://www.cantorsparadise.com/gradient-descent-simplified-421b437507c0?source=rss-7af47edd640c------2","_blank")}},{id:"post-fermi-paradox",title:'Fermi Paradox <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/intuition/fermi-paradox-87bc88f2f15a?source=rss-7af47edd640c------2","_blank")}},{id:"post-neural-network-the-dead-neuron",title:'Neural Network: The Dead Neuron <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/data-science/neural-network-the-dead-neuron-eaa92e575748?source=rss-7af47edd640c------2","_blank")}},{id:"post-radial-basis-function-neural-network-simplified",title:'Radial Basis Function Neural Network Simplified <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/data-science/radial-basis-function-neural-network-simplified-6f26e3d5e04d?source=rss-7af47edd640c------2","_blank")}},{id:"post-the-intuition-behind-the-naive-bayes-classifier",title:'The Intuition Behind The Naive Bayes\u2019 Classifier <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/intuition/the-intuition-behind-the-naive-bayes-classifier-629a64b3c6?source=rss-7af47edd640c------2","_blank")}},{id:"post-game-theory",title:'Game Theory <svg width="1.2rem" height="1.2rem" top=".5rem" viewbox="0 0 40 40" xmlns="http://www.w3.org/2000/svg"><path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path></svg>',description:"",section:"Posts",handler:()=>{window.open("https://medium.com/intuition/game-theory-79372317678b?source=rss-7af47edd640c------2","_blank")}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/projects/9_project/"}},{id:"social-email",title:"email",section:"Socials",handler:()=>{window.open("mailto:%6C%75%74%68%66%69%72%39%36@%67%6D%61%69%6C.%63%6F%6D","_blank")}},{id:"social-ieee",title:"IEEE Xplore",section:"Socials",handler:()=>{window.open("https://ieeexplore.ieee.org/author/37089211941/","_blank")}},{id:"social-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/luthfi-ramadhan","_blank")}},{id:"social-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@luthfir98","_blank")}},{id:"social-orcid",title:"ORCID",section:"Socials",handler:()=>{window.open("https://orcid.org/0000-0001-8571-8924","_blank")}},{id:"social-researchgate",title:"ResearchGate",section:"Socials",handler:()=>{window.open("https://www.researchgate.net/profile/Mgs_M_Ramadhan/","_blank")}},{id:"social-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=5BG0z7AAAAAJ","_blank")}},{id:"social-scopus",title:"Scopus",section:"Socials",handler:()=>{window.open("https://www.scopus.com/authid/detail.uri?authorId=57446469100","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>